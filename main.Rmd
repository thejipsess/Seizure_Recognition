---
title: "Seizure Recognition"
author: "Jip de Kok"
date: "9/15/2020"
output:
  html_document: default
  pdf_document: default
---

The data used here is EEG data. Originally there were 500 participants, who
were recorded for 23.5 seconds with 4097 data points per sample. Each sample
was divided into 23 chunks , each containing 178 data points for 1 second.
These chunks were shuffled, resulting in 11500 samples.


5 - (healthy, surface recording) eyes open, means when they were recording the EEG signal of the brain the patient had their eyes open
4 - (healthy, surface recording) eyes closed, means when they were recording the EEG signal the patient had their eyes closed
3 - (epiliptic, intracranial recording) The EEG activity from the hippocampal formation in the non-epiletogenic hemisphere with no seizure
2 - (epiliptic, intracranial recording) The EEG activity from the epileptogenic zone brain area with no seizure
1 - (epiliptic, intracranial recording) Recording of seizure activity

Seed used throughout this code: 4685

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


This section loads all the the required packages and the data. Also, it removes missing data and splits the data into dependant and independant data.
```{r data, echo=FALSE, message = FALSE}
# Set seed to ensure reproducibility
set.seed(4685)

# Load packages.R to install and load all the required packages and files
source('packages.R')

# Load data
x = read.csv('Data/data.csv', sep = ';', row.names = 'X')
# Remove rows with missing data
x <- na.omit(x)

# Randomly permute y to create randomised data
permute <- FALSE
if(permute){
  set.seed(4685)
  x$y <- sample(x$y)}
  
# Isolate y
y <- x$y

# remove y column from x
x <- subset(x, select = -y)

```

```{r Data_Inspection}
# Count missing data
nullsum = sum(!complete.cases(x))

# Set theme for plotting
theme_set(theme_bw(base_size=12)+ 
  theme(panel.grid.major = element_blank(),
  panel.grid.minor = element_blank()))

# Plot a random sample over time
plot_rand_sample(x)

```

```{r PCA}
# Perform PCA
pca <- prcomp(x, center = TRUE, scale=FALSE)

# Plot PCA
plot_pca(pca, y)

# Remove the sample with class 70
x <- x[y != 70,]
y <- y[y != 70]

```

```{r Plot_data_before}
# Create density plot of unnormalised data
plot_dens(x, "Data distribution (not pre-processed)")

# Make violin plots for the different classes
plot_violin(x, y, title = "violin plot for all classes (not pre-processed)")

# Create boxplots
plot_boxplot(x, y)
```


```{r Preprocessing}
# Get rid of the most extreme outlier (redundant)
row_max <- which(x == max(x), arr.ind = TRUE)[1]
y <- y[-row_max]
x <- x[-row_max,]


# Remove univariate outliers
for(i in seq(1, 178)){
  Q1 <- quantile(x[,i], 0.25)
  Q3 <- quantile(x[,i], 0.75)
  IQR <- Q3 - Q1
  uplim <- Q3 + 17*IQR
  downlim <- Q1 - 17*IQR
  
  y <- y[x[names(x)[i]] <= uplim & x[names(x)[i]] >= downlim]
  x <- x[x[names(x)[i]] <= uplim & x[names(x)[i]] >= downlim,]
}

# mean-center the data: Set mean of each variable to 0
preproc <- preProcess(x, method=c('center')) # Can also add 'scale'
x_norm <- predict(preproc, x)

# Min Max normalisation
for (col in colnames(x_norm)){
  x_norm[col] <- ((x_norm[col] - min(x_norm[col])) / (max(x_norm[col]) - min(x_norm[col])))
}

```


```{r Plot_data_after}
# Create density plot of unnormalised data
plot_dens(x_norm, "Data distribution (pre-processed)")

# Make violin plots for the different classes
plot_violin(x_norm, y, title = "violin plot for all classes (not pre-processed)")

# Create boxplots
plot_boxplot(x_norm, y)
```


``` {r distance, message=FALSE}
# create matrix z which contains both x and y, only for classes one and two
z <- x_norm
z$y <- y
z <- z[y == 1 | y == 2,]
z <- arrange(z, y)

# Calculate the distance matrix (euclidean distance)
distance <- dist(z[,-ncol(z)])
distance <- as.matrix(distance)

# Plot heatmap of the distance matrix
plot_heatmap(distance, save = TRUE, title = "Distance heatmap - no scaling")

# Perform double centring on the distance matrix
Rmean <- distance*0 + rowMeans(distance)
Cmean <- distance*0 + colMeans(distance)
distance = distance - Rmean - Cmean + mean(distance)

# Plot heatmap of the double centered distance matrix
plot_heatmap(distance, save = TRUE, title = "Distance heatmap - double centered")

# Perform PCA on normal data for class 1 & 2
pca <- prcomp(z[,-ncol(z)], center = TRUE, scale=FALSE)

# Plot PCA plots including 3D score plot
plot_pca(pca, y = z$y, title = "on class 1 & 2", save=TRUE, include_3D = TRUE, PC_x = 1, PC_y = 2, PC_z=3)

# Perform PCA on euclidean distance for class 1 & 2
pca_dist <- prcomp(distance, center = TRUE, scale=FALSE)

# Open new RGL device to allow both 3D plots to be active simultaneously
open3d()

# Plot distance PCA plots including 3D score plot
plot_pca(pca_dist, y = z$y, title = "on euclidean distance", save=TRUE, include_3D = TRUE, PC_x = 1, PC_y = 2, PC_z=3)
```

```{r rbf_kernel}
# Claculate the radial basis function kernel on z 
rbfkernel <- rbfdot(sigma = 0.01)
rbf_mat <- kernelMatrix(rbfkernel, as.matrix(subset(z, select = -y)))

# Calculate PCA of the kernel matrix
pca <- prcomp(rbf_mat, center = TRUE, scale=FALSE)

# Create PCA scatter plots of rbf kernel
plot_pca(pca, y = z$y, title = "kernel", save=TRUE, include_3D = TRUE, PC_x = 1, PC_y = 2, PC_z=3)
```

```{r gridsearch_rbf}
# Set Classes to use for classification
classes = c(1, 2)

# Split the data into train and test set using the function from 'Classification.R'
split_data <- split_test_train(x, y, classes = classes)
x_bin_train <- split_data$train
x_bin_test <- split_data$test

# Balance the data by random undersampling
# Determine the number of of samples in the biggest class
min_train_class <- min(table(split_data$train$y))
min_test_class <- min(table(split_data$test$y))

# Undersample the majority class(es) (UNCOMMENT NEXT LINES IF CLASSES ARE UNBALANCED)
x_bin_train <- ovun.sample(y ~ ., x_bin_train, method = 'under', N = min_train_class * length(classes), )$data
x_bin_test <- ovun.sample(y ~ ., x_bin_test, method = 'under', N = min_test_class * length(classes), )$data


# Check  if test and training set are balanced
print("Class balance of training set:")
print(table(x_bin_train$y)/length(x_bin_train$y)*100)
print("Class balance of test set:")
print(table(x_bin_test$y)/length(x_bin_test$y)*100)

# Create preprocessing recipe
SVM_recipe <-
    # Specify the recipe function, here the variable you want to predict should be put the left of the ~ sign,
    # and the predictor variables go to the right of the ~ symbol, since we want to use all other variables we use a dot (y ~ .)
    # We also specify data = x_bin_train such that the recipe will be based on the training data and we can apply an identical
    # transformation to the test set later on, and thus also to any other future data the model shoul be run on.
    recipe(y ~ ., data = x_bin_train) %>%
    # Set the mean of all predictor variables to 0
    step_center(all_predictors()) %>%
    # Here we fix the range of all the predictor variables of 0 to 1. (min-max normalisation)
    step_range(all_predictors(), min = 0, max = 1)

# Perform gridsearch
gridsearch_result <- gridsearch_svm_rbf(x_bin_train, SVM_recipe = SVM_recipe)

```

```{r SVM_rbg}
# Set seed to ensure reproducibility
set.seed(4685)

# Create svm model
svm <- svm_rbf(mode = "classification", cost = 10, rbf_sigma = 0.01)

# Fit the SVM model on t he training data
svm_fit <- 
  svm %>%
  set_engine("kernlab") %>%
  fit(y ~ ., x_bin_train)

# Evaluate the SVM model on the test data
test_results_rbf <- 
  x_bin_test$y %>%
  bind_cols(
    predict(svm_fit, x_bin_test)) %>%
  setNames(c('True class', 'Predicted class'))
  
# Compute the confusion matrix and evaluate the SVM performance
caret::confusionMatrix(factor(test_results_rbf[['Predicted class']]), factor(test_results_rbf[['True class']]))

# Generate PCA plot with svm misclassification information
correctly_classified_test <- test_results_rbf$'Predicted class' == test_results_rbf$'True class'

# PLot PCA of test sete with labels for misclassification
SVM_recipe <- prep(SVM_recipe, x_bin_train)
train_norm <- bake(SVM_recipe, x_bin_train)
test_norm <- bake(SVM_recipe, x_bin_test)
pca <- prcomp(subset(test_norm, select = -y), center = F, scale = F)
plot_pca(pca, correctly_classified_test, alpha = 0.5, title = "Test set with misclassifications", legend_title = 'Correct prediction')

# Plot PCA of training set and project test set onto it (this function is in  'plotter.R')
pca_projection(x_bin_train, x_bin_test, SVM_recipe)

# Plot density plots of the training and test before and after preprocessing
#plot_dens(data.frame(subset(test_norm, select = -y)))
#plot_dens(data.frame(subset(train_norm, select = -y)))
#plot_dens(data.frame(subset(x_bin_train, select = -y)))
#plot_dens(data.frame(subset(x_bin_test, select = -y)))
```
```{r gridsearch_lin}
# Set cost values to evaluate
cost_range = 10^(-3:1)

# Perform gridsearch
lin_model_opt = tune.svm(y ~ ., data = train_norm, type = "nu-classification", kernel = 'linear', cost = cost_range)

```


```{r SVM_lin}
# Set seed to ensure reproducibility
set.seed(4685)

# Create svm model
svm_lin <- svm(y ~ ., train_norm, scale = FALSE, type = "nu-classification", kernel = 'linear',  cost = 0.00001, probability = T)

# Evaluate the SVM model on the test data
test_results_lin <- 
  test_norm$y %>%
  bind_cols(
    predict(svm_lin, test_norm)) %>%
  setNames(c('True class', 'Predicted class'))

# Compute the confusion matrix and evaluate the SVM performance
caret::confusionMatrix(factor(test_results_lin[['Predicted class']]), factor(test_results_lin[['True class']]))
```

```{R roc}
# Predict probabilities on test set with rbf svm model
test_results_rbf <- 
  x_bin_test$y %>%
  bind_cols(
    predict(svm_fit, x_bin_test, type = 'prob')) %>%
  setNames(c('True class', 'Predicted class'))

# Predict probabilities on test set with linear svm model
test_results_lin <- 
  x_bin_test$y %>%
  bind_cols(
    attr(predict(svm_lin, x_bin_test, probability = T), 'probabilities')[,1]) %>%
  setNames(c('True class', 'Predicted class'))

# Create ROC curve for the linear and rbf svm models
par(pty = 's')
roc(as.numeric(test_results_rbf$'True class'), as.numeric(test_results_rbf$'Predicted class'), plot = T, legacy.axes = T,
     percent = T, xlab = "False postive %", ylab = "True positive %", print.auc = T, print.auc.y = 95, col = "cadetblue3")
plot.roc(as.numeric(test_results_lin$'True class'), as.numeric(test_results_lin$'Predicted class'), percent = T,
          print.auc = T, add = T, smoothed = F, col = "coral3")
legend(39, 20, legend=c("rbf", "linear"),
       col=c("cadetblue3", "coral3"), lty=1:2, cex=0.8)

```